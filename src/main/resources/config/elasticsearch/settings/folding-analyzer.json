{
    "analysis": {
        "analyzer": {
            "ascii_folding": {
                "tokenizer": "extended_whitespace",
                "filter": [
                    "lowercase",
                    "german_normalization",
                    "asciifolding"
                ]
            }
        },
        "tokenizer": {
            "extended_whitespace": {
                "type": "pattern",
                "pattern": "[^\\u00C0-\\u017Fa-z\\w+]+"
            }
        },
        "normalizer": {
            "ascii_lowercase": {
                "type": "custom",
                "char_filter": [],
                "filter": [
                    "lowercase",
                    "german_normalization",
                    "asciifolding"
                ]
            }
        }
    }
}
